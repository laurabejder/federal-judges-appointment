{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Federal Courts Project\n",
    "\n",
    "The ultimate goal of this project is to build a centralized database of federal judgeships across the 13 district appellate courts \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "and/or the 96 District courts in the United States. Because of the wealth of data involved, and the fact that much of this data is scattered across many pages and sites, the first step involves researching the domain, and developing a focus and range of data you want to obtain and make available.\n",
    "\n",
    "Here are three possible angles:\n",
    "\n",
    "1. Current judgeships, vacancies, and nomination proceedings: with this focus you would download tables of the recent vacancies and appointments, and go further into nomination procedures and Q&A's. This would entail a combination of scraping, conversions of PDFs, and using regular expressions to parse the PDFs (this is tough).\n",
    "\n",
    "2. Historical judgeships: with this focus you examine changes in federal judgeships over a certain period of time (perhaps 10 to 20 years). This would entail mainly the scraping of many pages and the integration of data about specific judges, ordered by district.\n",
    "\n",
    "3. Recent Nominations and confirmations:  this would focus specifically on judges newly nominated or appointed under the current administration. The focus would be more directly on the nomination hearings (Q&As), as well as the search for other data sources regarding the judges--news articles, opinions, writings by the judges.\n",
    "\n",
    "\n",
    "\n",
    "Your primary goal by Thursday is to come up with a specific research question: what kind of knowledge do you want to investigate, build and make available through this project. What are the central units of analysis? What do you want to reveal about the federal courts?\n",
    "\n",
    "Your secondary goal is to view the primary source pages and begin scraping. You do not have to have your central research question right at the beginning of the scraping, but it may help to have a direction.\n",
    "\n",
    "You're goal by Friday is to have a finalized architecture for your dataframe(s), any finalized list of sources that you will scrape/obtain.\n",
    "\n",
    "**Data Architecture**\n",
    "The question of architecture is central to this project. Because of the many possible angles, and the highly decentralized state of the primary source data, there is a wide range of designs for tables, rows, columns. You may want to begin scraping some of the main pages to get more familiar with what kind of rows and columns might be involved.\n",
    "\n",
    "**Interpretive architecture**\n",
    "This depends I how focused your data frame will be. If you pick specific districts, judges and/or confirmation hearings you may want to do more human reading to assess different ways the framing the politics/legal perspective of the judge or the district's decisions. If you choose to cast a wider net for your data, then you will want to focus on more quantitative categories for framing this: judges age, district, background, length of appointment, length of vacancy, number of vacancies, etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding considerations:\n",
    "While there is a great amount of data available, much of it is distributed across multiple pages, sometimes and inconsistent format. If you're interested in scraping nominations and downloading PDFs, you may want to consider using **selenium** for part of it. If you want to use beautiful soup, you will have to download links, and the loop through multiple pages to get a complete data set--unless your focus is more specific."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 1\n",
    "Scrape the first page of judicial vacancies:\n",
    "\n",
    "http://www.uscourts.gov/judges-judgeships/judicial-vacancies/current-judicial-vacancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Import your scraping libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "from playwright.async_api import async_playwright\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To awoid inventing a crazy loop I just run the same code for all 12 pages of information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "playwright = await async_playwright().start()\n",
    "browser = await playwright.chromium.launch(headless = False)\n",
    "page = await browser.new_page()\n",
    "\n",
    "await page.goto(\"https://www.congress.gov/search?q=%7B%22source%22%3A%22nominations%22%2C%22senate-committee%22%3A%22Judiciary%22%2C%22congress%22%3A%5B%22107%22%2C%22108%22%2C%22109%22%2C%22110%22%2C%22111%22%2C%22112%22%2C%22113%22%2C%22114%22%2C%22115%22%2C%22116%22%2C%22117%22%5D%7D&pageSize=250&page=1\")\n",
    "\n",
    "await page.content()\n",
    "doc = BeautifulSoup(await page.content(), 'html.parser')\n",
    "\n",
    "with open ('output1.html', 'w') as file:\n",
    "    file.write(str(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "playwright = await async_playwright().start()\n",
    "browser = await playwright.chromium.launch(headless = False)\n",
    "page = await browser.new_page()\n",
    "\n",
    "await page.goto(\"https://www.congress.gov/search?q=%7B%22source%22%3A%22nominations%22%2C%22senate-committee%22%3A%22Judiciary%22%2C%22congress%22%3A%5B%22107%22%2C%22108%22%2C%22109%22%2C%22110%22%2C%22111%22%2C%22112%22%2C%22113%22%2C%22114%22%2C%22115%22%2C%22116%22%2C%22117%22%5D%7D&pageSize=250&page=2\")\n",
    "\n",
    "await page.content()\n",
    "doc = BeautifulSoup(await page.content(), 'html.parser')\n",
    "\n",
    "with open ('output2.html', 'w') as file:\n",
    "    file.write(str(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "playwright = await async_playwright().start()\n",
    "browser = await playwright.chromium.launch(headless = False)\n",
    "page = await browser.new_page()\n",
    "\n",
    "await page.goto(\"https://www.congress.gov/search?q=%7B%22source%22%3A%22nominations%22%2C%22senate-committee%22%3A%22Judiciary%22%2C%22congress%22%3A%5B%22107%22%2C%22108%22%2C%22109%22%2C%22110%22%2C%22111%22%2C%22112%22%2C%22113%22%2C%22114%22%2C%22115%22%2C%22116%22%2C%22117%22%5D%7D&pageSize=250&page=3\")\n",
    "\n",
    "await page.content()\n",
    "doc = BeautifulSoup(await page.content(), 'html.parser')\n",
    "\n",
    "with open ('output3.html', 'w') as file:\n",
    "    file.write(str(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "playwright = await async_playwright().start()\n",
    "browser = await playwright.chromium.launch(headless = False)\n",
    "page = await browser.new_page()\n",
    "\n",
    "await page.goto(\"https://www.congress.gov/search?q=%7B%22source%22%3A%22nominations%22%2C%22senate-committee%22%3A%22Judiciary%22%2C%22congress%22%3A%5B%22107%22%2C%22108%22%2C%22109%22%2C%22110%22%2C%22111%22%2C%22112%22%2C%22113%22%2C%22114%22%2C%22115%22%2C%22116%22%2C%22117%22%5D%7D&pageSize=250&page=4\")\n",
    "\n",
    "await page.content()\n",
    "doc = BeautifulSoup(await page.content(), 'html.parser')\n",
    "\n",
    "with open ('output4.html', 'w') as file:\n",
    "    file.write(str(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "playwright = await async_playwright().start()\n",
    "browser = await playwright.chromium.launch(headless = False)\n",
    "page = await browser.new_page()\n",
    "\n",
    "await page.goto(\"https://www.congress.gov/search?q=%7B%22source%22%3A%22nominations%22%2C%22senate-committee%22%3A%22Judiciary%22%2C%22congress%22%3A%5B%22107%22%2C%22108%22%2C%22109%22%2C%22110%22%2C%22111%22%2C%22112%22%2C%22113%22%2C%22114%22%2C%22115%22%2C%22116%22%2C%22117%22%5D%7D&pageSize=250&page=5\")\n",
    "\n",
    "await page.content()\n",
    "doc = BeautifulSoup(await page.content(), 'html.parser')\n",
    "\n",
    "with open ('output5.html', 'w') as file:\n",
    "    file.write(str(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "playwright = await async_playwright().start()\n",
    "browser = await playwright.chromium.launch(headless = False)\n",
    "page = await browser.new_page()\n",
    "\n",
    "await page.goto(\"https://www.congress.gov/search?q=%7B%22source%22%3A%22nominations%22%2C%22senate-committee%22%3A%22Judiciary%22%2C%22congress%22%3A%5B%22107%22%2C%22108%22%2C%22109%22%2C%22110%22%2C%22111%22%2C%22112%22%2C%22113%22%2C%22114%22%2C%22115%22%2C%22116%22%2C%22117%22%5D%7D&pageSize=250&page=6\")\n",
    "\n",
    "await page.content()\n",
    "doc = BeautifulSoup(await page.content(), 'html.parser')\n",
    "\n",
    "with open ('output6.html', 'w') as file:\n",
    "    file.write(str(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "playwright = await async_playwright().start()\n",
    "browser = await playwright.chromium.launch(headless = False)\n",
    "page = await browser.new_page()\n",
    "\n",
    "await page.goto(\"https://www.congress.gov/search?q=%7B%22source%22%3A%22nominations%22%2C%22senate-committee%22%3A%22Judiciary%22%2C%22congress%22%3A%5B%22107%22%2C%22108%22%2C%22109%22%2C%22110%22%2C%22111%22%2C%22112%22%2C%22113%22%2C%22114%22%2C%22115%22%2C%22116%22%2C%22117%22%5D%7D&pageSize=250&page=7\")\n",
    "\n",
    "await page.content()\n",
    "doc = BeautifulSoup(await page.content(), 'html.parser')\n",
    "\n",
    "with open ('output7.html', 'w') as file:\n",
    "    file.write(str(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "playwright = await async_playwright().start()\n",
    "browser = await playwright.chromium.launch(headless = False)\n",
    "page = await browser.new_page()\n",
    "\n",
    "await page.goto(\"https://www.congress.gov/search?q=%7B%22source%22%3A%22nominations%22%2C%22senate-committee%22%3A%22Judiciary%22%2C%22congress%22%3A%5B%22107%22%2C%22108%22%2C%22109%22%2C%22110%22%2C%22111%22%2C%22112%22%2C%22113%22%2C%22114%22%2C%22115%22%2C%22116%22%2C%22117%22%5D%7D&pageSize=250&page=8\")\n",
    "\n",
    "await page.content()\n",
    "doc = BeautifulSoup(await page.content(), 'html.parser')\n",
    "\n",
    "with open ('output8.html', 'w') as file:\n",
    "    file.write(str(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "playwright = await async_playwright().start()\n",
    "browser = await playwright.chromium.launch(headless = False)\n",
    "page = await browser.new_page()\n",
    "\n",
    "await page.goto(\"https://www.congress.gov/search?q=%7B%22source%22%3A%22nominations%22%2C%22senate-committee%22%3A%22Judiciary%22%2C%22congress%22%3A%5B%22107%22%2C%22108%22%2C%22109%22%2C%22110%22%2C%22111%22%2C%22112%22%2C%22113%22%2C%22114%22%2C%22115%22%2C%22116%22%2C%22117%22%5D%7D&pageSize=250&page=9\")\n",
    "\n",
    "await page.content()\n",
    "doc = BeautifulSoup(await page.content(), 'html.parser')\n",
    "\n",
    "with open ('output9.html', 'w') as file:\n",
    "    file.write(str(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "playwright = await async_playwright().start()\n",
    "browser = await playwright.chromium.launch(headless = False)\n",
    "page = await browser.new_page()\n",
    "\n",
    "await page.goto(\"https://www.congress.gov/search?q=%7B%22source%22%3A%22nominations%22%2C%22senate-committee%22%3A%22Judiciary%22%2C%22congress%22%3A%5B%22107%22%2C%22108%22%2C%22109%22%2C%22110%22%2C%22111%22%2C%22112%22%2C%22113%22%2C%22114%22%2C%22115%22%2C%22116%22%2C%22117%22%5D%7D&pageSize=250&page=10\")\n",
    "\n",
    "await page.content()\n",
    "doc = BeautifulSoup(await page.content(), 'html.parser')\n",
    "\n",
    "with open ('output10.html', 'w') as file:\n",
    "    file.write(str(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "playwright = await async_playwright().start()\n",
    "browser = await playwright.chromium.launch(headless = False)\n",
    "page = await browser.new_page()\n",
    "\n",
    "await page.goto(\"https://www.congress.gov/search?q=%7B%22source%22%3A%22nominations%22%2C%22senate-committee%22%3A%22Judiciary%22%2C%22congress%22%3A%5B%22107%22%2C%22108%22%2C%22109%22%2C%22110%22%2C%22111%22%2C%22112%22%2C%22113%22%2C%22114%22%2C%22115%22%2C%22116%22%2C%22117%22%5D%7D&pageSize=250&page=11\")\n",
    "\n",
    "await page.content()\n",
    "doc = BeautifulSoup(await page.content(), 'html.parser')\n",
    "\n",
    "with open ('output11.html', 'w') as file:\n",
    "    file.write(str(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "playwright = await async_playwright().start()\n",
    "browser = await playwright.chromium.launch(headless = False)\n",
    "page = await browser.new_page()\n",
    "\n",
    "await page.goto(\"https://www.congress.gov/search?q=%7B%22source%22%3A%22nominations%22%2C%22senate-committee%22%3A%22Judiciary%22%2C%22congress%22%3A%5B%22107%22%2C%22108%22%2C%22109%22%2C%22110%22%2C%22111%22%2C%22112%22%2C%22113%22%2C%22114%22%2C%22115%22%2C%22116%22%2C%22117%22%5D%7D&pageSize=250&page=12\")\n",
    "\n",
    "await page.content()\n",
    "doc = BeautifulSoup(await page.content(), 'html.parser')\n",
    "\n",
    "with open ('output12.html', 'w') as file:\n",
    "    file.write(str(doc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0rc2 64-bit ('3.11.0rc2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "fa07e5dff76123542c28abca75c0e47ea742948dbeeb360ccfbd2a5c7c277f8b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
