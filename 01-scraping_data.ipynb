{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Federal Courts Project Guide\n",
    "\n",
    "The ultimate goal of this project is to build a centralized database of federal judgeships across the 13 district appellate courts and/or the 96 District courts in the United States. Because of the wealth of data involved, and the fact that much of this data is scattered across many pages and sites, the first step involves researching the domain, and developing a focus and range of data you want to obtain and make available.\n",
    "\n",
    "Here are three possible angles:\n",
    "\n",
    "1. Current judgeships, vacancies, and nomination proceedings: with this focus you would download tables of the recent vacancies and appointments, and go further into nomination procedures and Q&A's. This would entail a combination of scraping, conversions of PDFs, and using regular expressions to parse the PDFs (this is tough).\n",
    "\n",
    "2. Historical judgeships: with this focus you examine changes in federal judgeships over a certain period of time (perhaps 10 to 20 years). This would entail mainly the scraping of many pages and the integration of data about specific judges, ordered by district.\n",
    "\n",
    "3. Recent Nominations and confirmations:  this would focus specifically on judges newly nominated or appointed under the current administration. The focus would be more directly on the nomination hearings (Q&As), as well as the search for other data sources regarding the judges--news articles, opinions, writings by the judges.\n",
    "\n",
    "\n",
    "\n",
    "Your primary goal by Thursday is to come up with a specific research question: what kind of knowledge do you want to investigate, build and make available through this project. What are the central units of analysis? What do you want to reveal about the federal courts?\n",
    "\n",
    "Your secondary goal is to view the primary source pages and begin scraping. You do not have to have your central research question right at the beginning of the scraping, but it may help to have a direction.\n",
    "\n",
    "You're goal by Friday is to have a finalized architecture for your dataframe(s), any finalized list of sources that you will scrape/obtain.\n",
    "\n",
    "**Data Architecture**\n",
    "The question of architecture is central to this project. Because of the many possible angles, and the highly decentralized state of the primary source data, there is a wide range of designs for tables, rows, columns. You may want to begin scraping some of the main pages to get more familiar with what kind of rows and columns might be involved.\n",
    "\n",
    "**Interpretive architecture**\n",
    "This depends I how focused your data frame will be. If you pick specific districts, judges and/or confirmation hearings you may want to do more human reading to assess different ways the framing the politics/legal perspective of the judge or the district's decisions. If you choose to cast a wider net for your data, then you will want to focus on more quantitative categories for framing this: judges age, district, background, length of appointment, length of vacancy, number of vacancies, etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding considerations:\n",
    "While there is a great amount of data available, much of it is distributed across multiple pages, sometimes and inconsistent format. If you're interested in scraping nominations and downloading PDFs, you may want to consider using **selenium** for part of it. If you want to use beautiful soup, you will have to download links, and the loop through multiple pages to get a complete data set--unless your focus is more specific."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 1\n",
    "Scrape the first page of judicial vacancies:\n",
    "\n",
    "http://www.uscourts.gov/judges-judgeships/judicial-vacancies/current-judicial-vacancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Import your scraping libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "from playwright.async_api import async_playwright\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To awoid inventing a crazy loop I just run the same code for all 12 pages of information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "playwright = await async_playwright().start()\n",
    "browser = await playwright.chromium.launch(headless = False)\n",
    "page = await browser.new_page()\n",
    "\n",
    "await page.goto(\"https://www.congress.gov/search?q=%7B%22source%22%3A%22nominations%22%2C%22senate-committee%22%3A%22Judiciary%22%2C%22congress%22%3A%5B%22107%22%2C%22108%22%2C%22109%22%2C%22110%22%2C%22111%22%2C%22112%22%2C%22113%22%2C%22114%22%2C%22115%22%2C%22116%22%2C%22117%22%5D%7D&pageSize=250&page=1\")\n",
    "\n",
    "await page.content()\n",
    "doc = BeautifulSoup(await page.content(), 'html.parser')\n",
    "\n",
    "with open ('output1.html', 'w') as file:\n",
    "    file.write(str(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "playwright = await async_playwright().start()\n",
    "browser = await playwright.chromium.launch(headless = False)\n",
    "page = await browser.new_page()\n",
    "\n",
    "await page.goto(\"https://www.congress.gov/search?q=%7B%22source%22%3A%22nominations%22%2C%22senate-committee%22%3A%22Judiciary%22%2C%22congress%22%3A%5B%22107%22%2C%22108%22%2C%22109%22%2C%22110%22%2C%22111%22%2C%22112%22%2C%22113%22%2C%22114%22%2C%22115%22%2C%22116%22%2C%22117%22%5D%7D&pageSize=250&page=2\")\n",
    "\n",
    "await page.content()\n",
    "doc = BeautifulSoup(await page.content(), 'html.parser')\n",
    "\n",
    "with open ('output2.html', 'w') as file:\n",
    "    file.write(str(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "playwright = await async_playwright().start()\n",
    "browser = await playwright.chromium.launch(headless = False)\n",
    "page = await browser.new_page()\n",
    "\n",
    "await page.goto(\"https://www.congress.gov/search?q=%7B%22source%22%3A%22nominations%22%2C%22senate-committee%22%3A%22Judiciary%22%2C%22congress%22%3A%5B%22107%22%2C%22108%22%2C%22109%22%2C%22110%22%2C%22111%22%2C%22112%22%2C%22113%22%2C%22114%22%2C%22115%22%2C%22116%22%2C%22117%22%5D%7D&pageSize=250&page=3\")\n",
    "\n",
    "await page.content()\n",
    "doc = BeautifulSoup(await page.content(), 'html.parser')\n",
    "\n",
    "with open ('output3.html', 'w') as file:\n",
    "    file.write(str(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "playwright = await async_playwright().start()\n",
    "browser = await playwright.chromium.launch(headless = False)\n",
    "page = await browser.new_page()\n",
    "\n",
    "await page.goto(\"https://www.congress.gov/search?q=%7B%22source%22%3A%22nominations%22%2C%22senate-committee%22%3A%22Judiciary%22%2C%22congress%22%3A%5B%22107%22%2C%22108%22%2C%22109%22%2C%22110%22%2C%22111%22%2C%22112%22%2C%22113%22%2C%22114%22%2C%22115%22%2C%22116%22%2C%22117%22%5D%7D&pageSize=250&page=4\")\n",
    "\n",
    "await page.content()\n",
    "doc = BeautifulSoup(await page.content(), 'html.parser')\n",
    "\n",
    "with open ('output4.html', 'w') as file:\n",
    "    file.write(str(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "playwright = await async_playwright().start()\n",
    "browser = await playwright.chromium.launch(headless = False)\n",
    "page = await browser.new_page()\n",
    "\n",
    "await page.goto(\"https://www.congress.gov/search?q=%7B%22source%22%3A%22nominations%22%2C%22senate-committee%22%3A%22Judiciary%22%2C%22congress%22%3A%5B%22107%22%2C%22108%22%2C%22109%22%2C%22110%22%2C%22111%22%2C%22112%22%2C%22113%22%2C%22114%22%2C%22115%22%2C%22116%22%2C%22117%22%5D%7D&pageSize=250&page=5\")\n",
    "\n",
    "await page.content()\n",
    "doc = BeautifulSoup(await page.content(), 'html.parser')\n",
    "\n",
    "with open ('output5.html', 'w') as file:\n",
    "    file.write(str(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "playwright = await async_playwright().start()\n",
    "browser = await playwright.chromium.launch(headless = False)\n",
    "page = await browser.new_page()\n",
    "\n",
    "await page.goto(\"https://www.congress.gov/search?q=%7B%22source%22%3A%22nominations%22%2C%22senate-committee%22%3A%22Judiciary%22%2C%22congress%22%3A%5B%22107%22%2C%22108%22%2C%22109%22%2C%22110%22%2C%22111%22%2C%22112%22%2C%22113%22%2C%22114%22%2C%22115%22%2C%22116%22%2C%22117%22%5D%7D&pageSize=250&page=6\")\n",
    "\n",
    "await page.content()\n",
    "doc = BeautifulSoup(await page.content(), 'html.parser')\n",
    "\n",
    "with open ('output6.html', 'w') as file:\n",
    "    file.write(str(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "playwright = await async_playwright().start()\n",
    "browser = await playwright.chromium.launch(headless = False)\n",
    "page = await browser.new_page()\n",
    "\n",
    "await page.goto(\"https://www.congress.gov/search?q=%7B%22source%22%3A%22nominations%22%2C%22senate-committee%22%3A%22Judiciary%22%2C%22congress%22%3A%5B%22107%22%2C%22108%22%2C%22109%22%2C%22110%22%2C%22111%22%2C%22112%22%2C%22113%22%2C%22114%22%2C%22115%22%2C%22116%22%2C%22117%22%5D%7D&pageSize=250&page=7\")\n",
    "\n",
    "await page.content()\n",
    "doc = BeautifulSoup(await page.content(), 'html.parser')\n",
    "\n",
    "with open ('output7.html', 'w') as file:\n",
    "    file.write(str(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "playwright = await async_playwright().start()\n",
    "browser = await playwright.chromium.launch(headless = False)\n",
    "page = await browser.new_page()\n",
    "\n",
    "await page.goto(\"https://www.congress.gov/search?q=%7B%22source%22%3A%22nominations%22%2C%22senate-committee%22%3A%22Judiciary%22%2C%22congress%22%3A%5B%22107%22%2C%22108%22%2C%22109%22%2C%22110%22%2C%22111%22%2C%22112%22%2C%22113%22%2C%22114%22%2C%22115%22%2C%22116%22%2C%22117%22%5D%7D&pageSize=250&page=8\")\n",
    "\n",
    "await page.content()\n",
    "doc = BeautifulSoup(await page.content(), 'html.parser')\n",
    "\n",
    "with open ('output8.html', 'w') as file:\n",
    "    file.write(str(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "playwright = await async_playwright().start()\n",
    "browser = await playwright.chromium.launch(headless = False)\n",
    "page = await browser.new_page()\n",
    "\n",
    "await page.goto(\"https://www.congress.gov/search?q=%7B%22source%22%3A%22nominations%22%2C%22senate-committee%22%3A%22Judiciary%22%2C%22congress%22%3A%5B%22107%22%2C%22108%22%2C%22109%22%2C%22110%22%2C%22111%22%2C%22112%22%2C%22113%22%2C%22114%22%2C%22115%22%2C%22116%22%2C%22117%22%5D%7D&pageSize=250&page=9\")\n",
    "\n",
    "await page.content()\n",
    "doc = BeautifulSoup(await page.content(), 'html.parser')\n",
    "\n",
    "with open ('output9.html', 'w') as file:\n",
    "    file.write(str(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "playwright = await async_playwright().start()\n",
    "browser = await playwright.chromium.launch(headless = False)\n",
    "page = await browser.new_page()\n",
    "\n",
    "await page.goto(\"https://www.congress.gov/search?q=%7B%22source%22%3A%22nominations%22%2C%22senate-committee%22%3A%22Judiciary%22%2C%22congress%22%3A%5B%22107%22%2C%22108%22%2C%22109%22%2C%22110%22%2C%22111%22%2C%22112%22%2C%22113%22%2C%22114%22%2C%22115%22%2C%22116%22%2C%22117%22%5D%7D&pageSize=250&page=10\")\n",
    "\n",
    "await page.content()\n",
    "doc = BeautifulSoup(await page.content(), 'html.parser')\n",
    "\n",
    "with open ('output10.html', 'w') as file:\n",
    "    file.write(str(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "playwright = await async_playwright().start()\n",
    "browser = await playwright.chromium.launch(headless = False)\n",
    "page = await browser.new_page()\n",
    "\n",
    "await page.goto(\"https://www.congress.gov/search?q=%7B%22source%22%3A%22nominations%22%2C%22senate-committee%22%3A%22Judiciary%22%2C%22congress%22%3A%5B%22107%22%2C%22108%22%2C%22109%22%2C%22110%22%2C%22111%22%2C%22112%22%2C%22113%22%2C%22114%22%2C%22115%22%2C%22116%22%2C%22117%22%5D%7D&pageSize=250&page=11\")\n",
    "\n",
    "await page.content()\n",
    "doc = BeautifulSoup(await page.content(), 'html.parser')\n",
    "\n",
    "with open ('output11.html', 'w') as file:\n",
    "    file.write(str(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "playwright = await async_playwright().start()\n",
    "browser = await playwright.chromium.launch(headless = False)\n",
    "page = await browser.new_page()\n",
    "\n",
    "await page.goto(\"https://www.congress.gov/search?q=%7B%22source%22%3A%22nominations%22%2C%22senate-committee%22%3A%22Judiciary%22%2C%22congress%22%3A%5B%22107%22%2C%22108%22%2C%22109%22%2C%22110%22%2C%22111%22%2C%22112%22%2C%22113%22%2C%22114%22%2C%22115%22%2C%22116%22%2C%22117%22%5D%7D&pageSize=250&page=12\")\n",
    "\n",
    "await page.content()\n",
    "doc = BeautifulSoup(await page.content(), 'html.parser')\n",
    "\n",
    "with open ('output12.html', 'w') as file:\n",
    "    file.write(str(doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 2\n",
    "Scrape the first page of judicial confirmations:\n",
    "\n",
    "http://www.uscourts.gov/judges-judgeships/judicial-vacancies/confirmation-listing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3\n",
    "Investigate the judicial committee's confirmation postings:\n",
    "\n",
    "https://www.judiciary.senate.gov/nominations/confirmed\n",
    "\n",
    "This is relatively straightforward, except that the most interesting information is possibly PDFs of the questionnaires for each candidate. To get the PDFs you need to use selenium (see step 4), but first look this data and assess whether you think it will be useful to you. You can then parse them using regular expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Don't necessarily code here\n",
    "#Think about where you're going first\n",
    "#And read below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 4\n",
    "Investigate the judicial committee's hearings on nominees: \n",
    "\n",
    "https://www.judiciary.senate.gov/hearings\n",
    "\n",
    "This one is very tricky. It is where you can find PDFs with Q&A's from confirmation hearings. It is a multiple page scrape just to get links to various nomination pages, which then have links to PDFs, which is then have redirects to download the PDFs (you have to use selenium here). \n",
    "\n",
    "But before you do the scrape just go through the hearings pages by hand and click on where it says \"Nominations\". Look at the different Q&A's available and see if you think they will be useful to you. If they will be I can give you most of the code you will need to get the PDFs. Also, I have uploaded a file on slack of one hearings PDFs along with text conversions of them. Take a look at the text conversions, because you'll need to parse them using regular expressions.\n",
    "\n",
    "If you are interested in more historical data, look into the information on these links:\n",
    "\n",
    "Archives of vacancies/confirmations (if you want to build more historical data)\n",
    "http://www.uscourts.gov/judges-judgeships/judicial-vacancies/archive-judicial-vacancies\n",
    "\n",
    "Present and past judges including resumes:\n",
    "\n",
    "Appeals courts:\n",
    "https://www.fjc.gov/history/courts/u.s.-court-appeals-district-columbia-circuit-justices-and-judges\n",
    "\n",
    "District courts:\n",
    "https://www.fjc.gov/history/courts/u.s.-district-courts-and-federal-judiciary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Think about your focus and what your ultimate architecture should be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#More to come..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0rc2 64-bit ('3.11.0rc2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "fa07e5dff76123542c28abca75c0e47ea742948dbeeb360ccfbd2a5c7c277f8b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
